{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "punL79CN7Ox6"
      },
      "source": [
        "##### Copyright 2020 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_ckMIh7O7s6D"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ph5eir3Pf-3z"
      },
      "source": [
        "# Optimizing the Text Generation Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Uhzt6vVIB2"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l10c04_nlp_optimizing_the_text_generation_model.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCxhW3mtLmfb"
      },
      "source": [
        "You've already done some amazing work with generating new songs, but so far we've seen some issues with repetition and a fair amount of incoherence. By using more data and further tweaking the model, you'll be able to get improved results. We'll once again use the [Kaggle Song Lyrics Dataset](https://www.kaggle.com/mousehead/songlyrics) here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4aHK2CYygXom"
      },
      "source": [
        "## Import TensorFlow and related functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e70wxWoOVqC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2LmLTREBf5ng"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmLTO_dpgge9"
      },
      "source": [
        "## Get the Dataset\n",
        "\n",
        "As noted above, we'll utilize the [Song Lyrics dataset](https://www.kaggle.com/mousehead/songlyrics) on Kaggle again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "4Bf5FVHfganK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "567abb1b-f1aa-4b9c-9f0a-4212fd5708b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-31 02:00:38--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.197.139, 74.125.197.138, 74.125.197.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.197.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/21l6d91pdd48e9edtgabb57ucemaju5k/1680228000000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=6c21172d-7630-472d-9833-4808a8e4b293 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-03-31 02:00:39--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/21l6d91pdd48e9edtgabb57ucemaju5k/1680228000000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=6c21172d-7630-472d-9833-4808a8e4b293\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 74.125.20.132, 2607:f8b0:400e:c07::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv   100%[===================>]  69.08M  75.9MB/s    in 0.9s    \n",
            "\n",
            "2023-03-31 02:00:40 (75.9 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz9x-7dWihxx"
      },
      "source": [
        "## 250 Songs\n",
        "\n",
        "Now we've seen a model trained on just a small sample of songs, and how this often leads to repetition as you get further along in trying to generate new text. Let's switch to using the 250 songs instead, and see if our output improves. This will actually be nearly 10K lines of lyrics, which should be sufficient.\n",
        "\n",
        "Note that we won't use the full dataset here as it will take up quite a bit of RAM and processing time, but you're welcome to try doing so on your own later. If interested, you'll likely want to use only some of the more common words for the Tokenizer, which will help shrink processing time and memory needed (or else you'd have an output array hundreds of thousands of words long)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWbMN_19jfRT"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LRmPPJegovBe"
      },
      "outputs": [],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kIGedF3XjHj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f188ef14-8d16-4e46-ca98-2e8c1701571e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-fbdddccf8583>:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        }
      ],
      "source": [
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "# Read the dataset from csv - this time with 250 songs\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:250]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
        "total_words = tokenizer.num_words\n",
        "\n",
        "# There should be a lot more words now\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quoDmw_FkNBA"
      },
      "source": [
        "### Create Sequences and Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kkLAf3HmkPSo"
      },
      "outputs": [],
      "source": [
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cECbqT-blMk-"
      },
      "source": [
        "### Train a (Better) Text Generation Model\n",
        "\n",
        "With more data, we'll cut off after 100 epochs to avoid keeping you here all day. You'll also want to change your runtime type to GPU if you haven't already (you'll need to re-run the above cells if you change runtimes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7nHOp6uWlP_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93109599-ba7d-40be-8b87-ad7492f5fff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1480/1480 [==============================] - 35s 15ms/step - loss: 5.9846 - accuracy: 0.0462\n",
            "Epoch 2/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 5.6755 - accuracy: 0.0521\n",
            "Epoch 3/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 5.4579 - accuracy: 0.0699\n",
            "Epoch 4/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 5.2537 - accuracy: 0.0942\n",
            "Epoch 5/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 5.0850 - accuracy: 0.1105\n",
            "Epoch 6/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 4.9446 - accuracy: 0.1211\n",
            "Epoch 7/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.8146 - accuracy: 0.1336\n",
            "Epoch 8/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.6827 - accuracy: 0.1478\n",
            "Epoch 9/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.5607 - accuracy: 0.1623\n",
            "Epoch 10/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.4502 - accuracy: 0.1766\n",
            "Epoch 11/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 4.3463 - accuracy: 0.1886\n",
            "Epoch 12/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.2541 - accuracy: 0.2007\n",
            "Epoch 13/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.1619 - accuracy: 0.2130\n",
            "Epoch 14/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 4.0783 - accuracy: 0.2254\n",
            "Epoch 15/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.9999 - accuracy: 0.2360\n",
            "Epoch 16/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.9285 - accuracy: 0.2453\n",
            "Epoch 17/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.8622 - accuracy: 0.2553\n",
            "Epoch 18/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.8023 - accuracy: 0.2639\n",
            "Epoch 19/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.7440 - accuracy: 0.2717\n",
            "Epoch 20/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.6907 - accuracy: 0.2779\n",
            "Epoch 21/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 3.6386 - accuracy: 0.2849\n",
            "Epoch 22/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.5951 - accuracy: 0.2899\n",
            "Epoch 23/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.5582 - accuracy: 0.2977\n",
            "Epoch 24/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.5136 - accuracy: 0.3033\n",
            "Epoch 25/100\n",
            "1480/1480 [==============================] - 18s 12ms/step - loss: 3.4645 - accuracy: 0.3110\n",
            "Epoch 26/100\n",
            "1480/1480 [==============================] - 14s 9ms/step - loss: 3.4286 - accuracy: 0.3163\n",
            "Epoch 27/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3920 - accuracy: 0.3234\n",
            "Epoch 28/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3642 - accuracy: 0.3270\n",
            "Epoch 29/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3311 - accuracy: 0.3316\n",
            "Epoch 30/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.3080 - accuracy: 0.3338\n",
            "Epoch 31/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.2722 - accuracy: 0.3419\n",
            "Epoch 32/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.2333 - accuracy: 0.3472\n",
            "Epoch 33/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.2045 - accuracy: 0.3501\n",
            "Epoch 34/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.1906 - accuracy: 0.3529\n",
            "Epoch 35/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.1584 - accuracy: 0.3572\n",
            "Epoch 36/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.1334 - accuracy: 0.3616\n",
            "Epoch 37/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.1082 - accuracy: 0.3667\n",
            "Epoch 38/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0875 - accuracy: 0.3703\n",
            "Epoch 39/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0640 - accuracy: 0.3741\n",
            "Epoch 40/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0426 - accuracy: 0.3767\n",
            "Epoch 41/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 3.0381 - accuracy: 0.3786\n",
            "Epoch 42/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.0139 - accuracy: 0.3808\n",
            "Epoch 43/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9873 - accuracy: 0.3862\n",
            "Epoch 44/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9629 - accuracy: 0.3914\n",
            "Epoch 45/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9572 - accuracy: 0.3909\n",
            "Epoch 46/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9285 - accuracy: 0.3961\n",
            "Epoch 47/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.9101 - accuracy: 0.3989\n",
            "Epoch 48/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8981 - accuracy: 0.4014\n",
            "Epoch 49/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8794 - accuracy: 0.4034\n",
            "Epoch 50/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8657 - accuracy: 0.4065\n",
            "Epoch 51/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8451 - accuracy: 0.4109\n",
            "Epoch 52/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.8353 - accuracy: 0.4099\n",
            "Epoch 53/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.8113 - accuracy: 0.4166\n",
            "Epoch 54/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.8013 - accuracy: 0.4170\n",
            "Epoch 55/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.7985 - accuracy: 0.4195\n",
            "Epoch 56/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.7692 - accuracy: 0.4239\n",
            "Epoch 57/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.7512 - accuracy: 0.4280\n",
            "Epoch 58/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7370 - accuracy: 0.4302\n",
            "Epoch 59/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7472 - accuracy: 0.4275\n",
            "Epoch 60/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.7146 - accuracy: 0.4331\n",
            "Epoch 61/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6968 - accuracy: 0.4378\n",
            "Epoch 62/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6866 - accuracy: 0.4399\n",
            "Epoch 63/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6806 - accuracy: 0.4390\n",
            "Epoch 64/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6698 - accuracy: 0.4391\n",
            "Epoch 65/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6618 - accuracy: 0.4414\n",
            "Epoch 66/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6440 - accuracy: 0.4452\n",
            "Epoch 67/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6337 - accuracy: 0.4465\n",
            "Epoch 68/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6168 - accuracy: 0.4495\n",
            "Epoch 69/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.6120 - accuracy: 0.4487\n",
            "Epoch 70/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5948 - accuracy: 0.4544\n",
            "Epoch 71/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5809 - accuracy: 0.4564\n",
            "Epoch 72/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.5791 - accuracy: 0.4562\n",
            "Epoch 73/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5751 - accuracy: 0.4573\n",
            "Epoch 74/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5566 - accuracy: 0.4607\n",
            "Epoch 75/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5453 - accuracy: 0.4629\n",
            "Epoch 76/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5372 - accuracy: 0.4632\n",
            "Epoch 77/100\n",
            "1480/1480 [==============================] - 13s 8ms/step - loss: 2.5505 - accuracy: 0.4615\n",
            "Epoch 78/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5140 - accuracy: 0.4690\n",
            "Epoch 79/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5292 - accuracy: 0.4643\n",
            "Epoch 80/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4996 - accuracy: 0.4714\n",
            "Epoch 81/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4885 - accuracy: 0.4729\n",
            "Epoch 82/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4862 - accuracy: 0.4724\n",
            "Epoch 83/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4763 - accuracy: 0.4754\n",
            "Epoch 84/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4660 - accuracy: 0.4759\n",
            "Epoch 85/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4557 - accuracy: 0.4784\n",
            "Epoch 86/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4657 - accuracy: 0.4765\n",
            "Epoch 87/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4497 - accuracy: 0.4786\n",
            "Epoch 88/100\n",
            "1480/1480 [==============================] - 13s 9ms/step - loss: 2.4307 - accuracy: 0.4830\n",
            "Epoch 89/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4336 - accuracy: 0.4816\n",
            "Epoch 90/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4264 - accuracy: 0.4844\n",
            "Epoch 91/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4080 - accuracy: 0.4868\n",
            "Epoch 92/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4019 - accuracy: 0.4857\n",
            "Epoch 93/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.4009 - accuracy: 0.4872\n",
            "Epoch 94/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3895 - accuracy: 0.4891\n",
            "Epoch 95/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3782 - accuracy: 0.4916\n",
            "Epoch 96/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3991 - accuracy: 0.4880\n",
            "Epoch 97/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3942 - accuracy: 0.4886\n",
            "Epoch 98/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3692 - accuracy: 0.4924\n",
            "Epoch 99/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3535 - accuracy: 0.4959\n",
            "Epoch 100/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3431 - accuracy: 0.4987\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgvIz20nlQcq"
      },
      "source": [
        "### View the Training Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rOqmmarvlSLh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "bd8f0b16-32f4-4977-de19-a053403d2e80"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISLZZGlQlSxh"
      },
      "source": [
        "### Generate better lyrics!\n",
        "\n",
        "This time around, we should be able to get a more interesting output with less repetition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "P96oVMk3lU7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691ad15e-236b-4719-c2b0-e63d44b463cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 685ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "im feeling chills to love the nile i adore you love you once is the of me into the sky soul soul rather be world world outta chat maybe brighter outta regret cheap while than thats the sensation of me and get two things for me can do it be insane and yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah yeah\n"
          ]
        }
      ],
      "source": [
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgJKV8_oRU9"
      },
      "source": [
        "### Varying the Possible Outputs\n",
        "\n",
        "In running the above, you may notice that the same seed text will generate similar outputs. This is because the code is currently always choosing the top predicted class as the next word. What if you wanted more variance in the output? \n",
        "\n",
        "Switching from `model.predict_classes` to `model.predict_proba` will get us all of the class probabilities. We can combine this with `np.random.choice` to select a given predicted output based on a probability, thereby giving a bit more randomness to our outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lZe9gaJeoGVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "829862ca-b3c5-4ff8-a23c-ed8f290b9cf6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "141\n"
          ]
        }
      ],
      "source": [
        "# Test the method with just the first word after the seed text\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "predicted_probs = model.predict(token_list)[0]\n",
        "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
        "                             p=predicted_probs)\n",
        "# Running this cell multiple times should get you some variance in output\n",
        "print(predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ee7WKgRGrJy1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9d91ff-29d3-40bc-cd79-9cfac3c9437f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "im feeling chills to gonna answer you please let me start a man i aint me we can take one life awhile enough one those was friends mental way shoes mad at married really dream music in a coat straight to are of the mood for me dont win returning it away how i think sitting out for time thats girl youre flat lovers all free baby for another other praying that feelings nights sensation as ocean fat rather ending cries all spend babe at things life to talk for fortune pretty wedding guess as she catches so strange dreams borrow kinda lover\n"
          ]
        }
      ],
      "source": [
        "# Use this process for the full output generation\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted_probs = model.predict(token_list)[0]\n",
        "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
        "                               p=predicted_probs)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}